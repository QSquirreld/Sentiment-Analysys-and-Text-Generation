# Sentiment Analysis and Generation

Проект демонстрирует реализацию end-to-end пайплайна: от анализа тональности отзывов до генерации стилизованных ответов на них с помощью языковой модели. <br>Пример применения NLP-подходов на реальных открытых данных из бизнеса.

## Цель

Построить систему, которая:
- **Анализирует тональность** отзывов пользователей (положительная / нейтральная / негативная);
- **Генерирует стилизованные ответы** в корпоративном стиле с учётом тональности;
- Использует **предобученные модели** и **few-shot prompting** без необходимости в дообучении LLM.

## Датасет

[`Yelp/yelp_review_full`](https://huggingface.co/datasets/Yelp/yelp_review_full) — датасет с отзывами пользователей о различных продуктах, сервисах и услугах, на разных языках, содержащий оценки от 0 до 5.

- **Тип**: Классификация текста и Классификация сентимента
- **Язык**: Английский
- **Размер**: 650k примеров
- **Разметка**:
  - 1 — очень негативный  
  - 2 — негативный  
  - 3 — нейтральный  
  - 4 — положительный  
  - 5 — очень положительный
- **Использование**:  
  Отзывы используются в двух задачах::  
    1. **Для классификации** — модель на основе BERT определяет уровень сентимента (оценку от 1 до 3).  
    2. **Для генерации** — те же отзывы служат входными данными для языковой модели, которая, опираясь на текст и определённый сентимент, генерирует соответствующую реакцию.

## Структура проекта

### 1. **Классификация отзывов**

- Загрузка и предобработка [датасета](#датасет)
    - Нормализация (Очистка текста от лишних символов, эмодзи и т.д.)
    - Переразметка классов с целью сокращения до 3х (neg, neutral, pos)
    - Выравнивание количества классов
- Токенизация с паддингом (`Data Collator`)
- Настройка параметров обучения и само обучение [`roberta-base`](https://huggingface.co/roberta-base)  
- Оценка `classification_report` и `ConfusionMatrix`
- One-Shot тестирование

### 2. **Генерация ответов**
- Инференс [`Mistral-7B-Instruct-v0.1-GPTQ`](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GPTQ)
- Применяется **few-shot prompting**:
  - В prompt вручную добавлены 2–3 примера отзывов и ответов;
  - Это помогает модели генерировать **корректные и вежливые ответы** в нужном стиле.
- One-Shot тестирование
- Вычисление метрик `ROUGE-1`, `ROUGE-L` и `Semantic Similarity`

Пример пайплайна:
```
Отзыв: "Слишком долго ждал заказа"
Класс: Негативный
Ответ: Нам жаль, что вам пришлось ждать. Мы постараемся ускорить доставку в будущем.
```

## Используемые модели

- **Для сентимент-анализа**: [`roberta-base`](https://huggingface.co/roberta-base)  
    - Классическая BERT-подобная модель.
    - Используется для определения тональности пользовательских отзывов (от 1 до 5).

- **Для генерации ответов**: [`TheBloke/Mistral-7B-Instruct-v0.1-GPTQ`](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GPTQ)
    - Квантованная версия мощной языковой модели Mistral-7B, оптимизированная для запуска на ограниченных ресурсах.
    - Используется в режиме **instruction-following** для генерации реплик на основе сентимента и текста отзыва.

## Метрики

### Сентимент-анализ

**Classification Report:**

| Class | Precision | Recall | F1-score | Support |
|-------|-----------|--------|----------|---------|
| 0     | 0.90      | 0.90   | 0.90     | 1061    |
| 1     | 0.55      | 0.64   | 0.59     | 474     |
| 2     | 0.90      | 0.83   | 0.86     | 965     |

| Metric       | Value |
|--------------|-------|
| Accuracy     | 0.82  |
| Macro avg    | 0.78  |
| Weighted avg | 0.83  |

**Confusion Matrix:**

[![image.png](https://i.postimg.cc/6qTHhyyG/image.png)](https://postimg.cc/RJ5QSC1M)

### Генерация ответов
- Метрики генерации:
  - **ROUGE-1**: `0.31`
  - **ROUGE-L**: `0.31`
  - **Semantic Similarity**: `0.30`

## Результаты

- Модель **уверенно классифицирует** отзывы на три класса.
- Генерация происходит **контролируемо**, с учётом тональности и заданного стиля.
- Few-shot prompting обеспечивает быстрое приближение к нужному стилю без дополнительного обучения.

## Применение

Проект может использоваться в:
- Онлайн-магазинах — для автоматических ответов на отзывы;
- CRM-системах — для анализа клиентских фидбеков;
- Чат-ботах — для персонализированной коммуникации.

## Возможные доработки

- Использовать **PEFT / LoRA** для дообучения генератора на кастомных ответах;
- Добавить **реакции на конкретные аспекты** (например, доставка, качество товара и т.п.);
- Реализовать **анализ тональности с помощью LLM**, чтобы не разделять классификатор и генератор;
- Увеличить корпус шаблонов и таргетных ответов для генерации.
